---
layout: post
title: Hadoop生态之HBase —— 一、初识
category: 技术
tags: Hadoop HBase
keywords: Hadoop HBase
description: Hadoop生态之HBase第一篇
---

### 1 背景介绍

#### 1.1 什么是HBASE

首先HBase是数据库，是基于HDFS、分布式、**面向列**的数据库，能满足实时**随机读写**大规模的数据集[^1]。其次，HBase是结构松散的，跟MySQL不一样，它每一行的结构都可以不同，且都是以字符串的方式进行存储。


#### 1.2 为什么会有HBase

Bigtable出现原因：
- 数据量太大，远超传统关系型数据库所能承受的范围（也许能存放得下，但机器或者license需要的钱估计会让google很肉疼）
- 光靠传统的关系型数据库或者MapReduce，已经难以满足大规模数据实时处理应用的需求

2006年Powerset的员工基于Google的论文 "[Bigtable: A Distributed Storage System for Structured Data](https://ai.google/research/pubs/pub27898)" 进行实现，原理与Bigtable基本一致。2007年10月的时候发布了第一版，10年5月成为Apache顶级项目。

#### 1.3 HBase在Hadoop生态中的位置

![Hadoop EcoSystem](https://www.mssqltips.com/tipimages2/3260_Apache_Hadoop_Ecosystem.JPG)

- HBase通常都是用来存储海量数据，如果只是小几百万数据则不需要HBase，适合在时延较敏感的场景中使用
- 跟Hive一样，数据最终还是落地到HDFS上，默认三副本
- Hive虽然在查询语句方面较为友好，但其查询过程会转化成MR作业，速度上无法和HBase相比

### 2 技术介绍

#### 2.1 系统架构

![HBase基本架构](https://www.ibm.com/developerworks/cn/data/library/techarticle/dm-1306zhanglp/1.gif)

- Master  
    - 管理用户对表的增删改查等操作
    - 维护Region服务器列表
    - 负责在Region分裂或合并后，重新调整Region的分布
    - 负载均衡

- RegionServers
    - 负责存储和维护分配给自己的Region(HBase高可用和分布式的基本单元)
    - 处理来自客户端的读写请求

- zookeeper
    - 保障Master的高可用
    - 监视Region服务器的状态
    - 通知Master哪些Region服务器发生故障不可用

#### 2.2 数据结构

BigTable的论文中提到：  
> A Bigtable is a sparse, distributed, persistent multi-dimensional sorted map.

基本上可以将HBase表看成稀疏的Map结构。其主要的概念包括：
- namespace (类似于MySQL的数据库角色，可用于数据范围控制)
- tableName
- columnFamily (列簇，相近属性的列的集合)
- qualifier (类似于列名)
- version (除主键外，其他值都有版本，默认格式是时间戳，可自定义)
- rowKey (类似于主键的概念)

实际例子： `dwa:userInfo` 表，包括*i* 和*s* 两个列簇，分别是info 和score的缩写

rowKey | i:name | i:gender | i:age | s:math | s:english | s:history | s:science
---    |  ---   |   ---    |  ---  |  ---   |   ---    | --- | ---
04058102 | 张三 | 男 | 24 | 89 | 80 | 60 | 93
14057102 | 李四 | 男 | 25 | 80 | 89 | 62 (version:2018) 50(version:2017) |

表中包含2条记录，学号分别是20185040和20175041的两个学生的基本信息以及选课成绩。   
其中翻转学号作为主键，张三选了科学的选修课，而李四没有，同时李四在去年的历史考试中挂了。   
例子中的自定义版本的做法官方并不推荐。

需要注意的几个点包括：
- 每一行都是根据rowKey排序的，上面的例子如果直接拿学号作为主键，则李四会排在张三前面
- 列簇是HBase表的基本控制单元，不同列簇下的列保存在不同的HFile中，所以也解释了压缩的属性也是列簇级别而不是表级别。另外，列簇的数量不宜过多[^2]，且长度尽量短
- 没有“修改”的方法，除rowKey外，其他值按多版本来实现更新。0.96版本后，默认只保留一个版本[^3]。
- 空值的话不会显示，也不会存在文件中

### 3 基本API

#### 3.1 HBase shell

HBase shell的常用操作（HBase shell大概是我用过的最难用的一个，退格的时候一定要按住ctrl键）
```
# namespace
list_namespace
create_namespace 'dwa'
list_namespace_tables 'dwa'
drop_namespace 'dwa'

# table
create 'dwa:useInfo', 'i','s'
list // show tables();
desc 'dwa:userInfo'

# insert and select by id
put 'dwa:userInfo', '04058102', 'i:name', '张三'
put 'dwa:userInfo', '04058102', 'i:gender', '男'
put 'dwa:userInfo', '04058102', 'i:age', '25'
get 'dwa:userInfo', '04058102' 

scan 'dwa:userInfo' , LIMIT=>1
```
#### 3.2 Java
1. 主要依赖
```XML
<dependency>
     <groupId>org.apache.hbase</groupId>
     <artifactId>hbase-client</artifactId>
     <version>1.1.2</version>
</dependency>
```
2. 需要hdfs-site.xml, hbase-site.xml, core-site.xml配置文件
3. 需要将hbase-site.xml中的hostname在host中添加
4. 获得HBaseAdmin对象、hTable对象
```Java
Configuration config = HBaseConfiguration.create();
Connection conn = ConnectionFactory.createConnection(config);
HBaseAdmin hBaseAdmin = new HBaseAdmin(config); 

// Disable, and then delete the table
admin.disableTable("people");
admin.deleteTable("people");

// get result from hTable by rowKey
hTable = (HTable) conn.getTable(TableName.valueOf(“dwa:userInfo”));
Get get = new Get(Bytes.toBytes("14057102"));
Result res = hTable.get(get);
for (Cell cell : res.rawCells()) {
    String cloneFamily = Bytes.toString(CellUtil.cloneFamily(cell));
    String cloneQualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
    String value = Bytes.toString(CellUtil.cloneValue(cell));
    reslutMap.put(cloneFamily + ":" + cloneQualifier, value);
}

// scan
Scan scan = new Scan();
scan.setStartRow(Bytes.toBytes("stKey"));
scan.setStopRow(Bytes.toBytes("edKey"));
ResultScanner resultScann1 = hTable.getScanner(scan);
for(Result r:resultScann1){

}
// put new row
Put theput= new Put(Bytes.toBytes("04058102"));
theput.add(Bytes.toBytes("i"),Bytes.toBytes("name"),Bytes.toBytes("张三"));
hTable.put(theput);
```

### 参考资料

[HBase book](http://hbase.apache.org/book.html#regions.arch)  
[Bigtable: A Distributed Storage System for Structured Data](https://ai.google/research/pubs/pub27898)
---

[^1]: > Apache HBase™ is the Hadoop database, a distributed, scalable, big data store. 
Use Apache HBase™ when you need random, realtime read/write access to your Big Data.

[^2]: > HBase currently does not do well with anything about two or three column families so keep the number of column families in your schema low.

[^3]: > Prior to HBase 0.96, the default number of versions kept was 3, but in 0.96 and newer has been changed to 1.
