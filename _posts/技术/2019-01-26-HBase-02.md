---
layout: post
title: Hadoop生态之HBase —— 二、存储
category: 技术
tags: Hadoop HBase
keywords: Hadoop HBase
description: Hadoop生态之HBase第二篇
---

#### 1 HBASE与HDFS

在笔者接触的应用中，HBase的数据都是保存在HDFS中的（当然也支持amazon的s3），那么HBase表中的数据是如何保存到HDFS中并实现毫秒级的写入和读取的呢？本文将对这个问题进行**简单**地回答，首先让我们回顾下第一篇的知识点。

**1.1 HBASE表结构回顾**

HBASE表包括：`nameSpace`,`tableName`,`rowKey`, `columnFamily`,`qualifier`和`version`等概念，同一个命名空间的表在HDFS中会存放在同一目录下。
当HBase表的数据超过一定大小时，会**横向**拆分成多个`Region`（根据HBASE版本不同，默认的拆分策略也不同），根据列簇的数量，每个`Region`又包含多个`Store`。一个`Store`下包含多个`StoreFile`(`HFile`)以及一个在内存中的`MemStore`。

结构如下所示：[^region]
> Table (HBase table) 
> - Region (Regions for the table)
>   - Store (Store per ColumnFamily for each Region for the table)  
>       - MemStore (MemStore for each Store for each Region for the table)  
>       - StoreFile (StoreFiles for each Store for each Region for the table)  
>           - Block (Blocks within a StoreFile within a Store for each Region for
the table)

在下图`HRegionServer`中也可以看到结构示意：
![](http://dl.iteye.com/upload/attachment/0068/7738/2b259b30-489d-37ef-b778-a0f667dd17ea.jpg)


总结：HBASE表横向切分成多个`Region`，存放在多台`RegionServer`上。每个`region`按列簇分别存储在`StoreFile`中（因此建议一张表不宜包含3个以上的列簇，且查询时尽可能查询同一个列簇下的数据），记录按顺序写入，并且一旦写入就不能再修改（修改某个key的值也只是添加新版本的数据）。

**1.2 HBASE在HDFS中的目录结构**

HBASE的数据存放在HDFS中哪个位置，是由配置文件`hbase-site.xml`中`hbase.rootdir`决定的，通常是在HDFS的hbase目录下。目录结构如下所示：其中最关键的就是data和WALs目录。

```
- .tmp               //临时存放刚开始创建/删除的表
- WALs               //writeAheadLogs
- archive            //表的归档和快照
- corrupt            //存放损坏的日志文件
- data               //表数据文件夹
hbase.id            //记录HBASE进程的ID
hbase.version       //表明HFile文件的版本信息
- oldWALs           //已经持久化到磁盘的log文件
```

#### 2 HBASE存储设计

HBASE快速写入和高可用的特性很大程度上依靠的是**LSM思想**，LSM树(Log-Structured Merge Tree)简单地说就是将对数据的操作（除了读操作）先写在内存中，到达一定大小后再写入磁盘文件，以实现高速写入的目的。同时，HBASE会定时对文件进行合并，以减少读操作时需要访问的文件数量，提高读效率。

**写操作流程简述**
1. 客户端发起对数据写操作请求时，先检查`memStore`是否存在记录，没有的话就写到HLog（WALs）和`memStore`中。一台`RegionServer`默认只有一个HLog文件，对不同`Region`的操作都写到同一个HLog中，主要是在恢复数据的时候会用到，具体细节以后再介绍。
2. 内存中的`memStore`大小超过阈值后，就会落地到`StoreFile`文件，
3. 跟`memStore`类似，HLog在超过一定大小后，也会拆分成多个HLog文件（不再有记录写入）。当HLog记录的操作都落地到磁盘后，该文件也会被移动到`oldWALs`文件夹，等待删除。

至此，一条写数据的操作经过`HLog`和`memStore`，最终落地到`StoreFile`。相对应地，从`region`读数据的时候，会先检查`memStore`中是否存在，不存在的情况下才会去`StoreFile`中进行查找，而一个`region`包含了多个`StoreFile`文件，如何快速判断一个文件是否包含目标数据则涉及到布隆过滤器的知识，同样等之后再做详细介绍。


#### 3 HDFS查看StoreFile

`StoreFiles` 是数据实际保存的地方，每次`memStore`的大小超过阈值后，就会刷写到文件中产生`StoreFile`。Hbase在后面也会对多个`StoreFile`进行不同级别的合并操作，以减少小文件的数量，提高读操作的速度。

**3.1 StoreFile路径**

`StoreFile`在HDFS中位置结构：[^2]
```
/hbase
    /data
        /<Namespace>                    (Namespaces in the cluster)
            /<Table>                    (Tables in the cluster)
                /<Region>               (Regions for the table)
                    /<ColumnFamily>     (ColumnFamilies for the Region for the table)
                        /<StoreFile>    (StoreFiles for the ColumnFamily for the Regions for the table)
```

1. 查看某张表下有多少个region
```
hadoop fs -ls /hbase/data/dwa/userInfo
Found 3 items
/hbase/data/dwa/userInfo/.tabledesc
/hbase/data/dwa/userInfo/.tmp
/hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de
```
2. 查看region下有几个列簇
```
hadoop fs -ls /hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de
Found 3 items
/hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de/.regioninfo
/hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de/i
/hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de/recovered.edits
```
3. 查看列簇下的[StoreFile](https://hbase.apache.org/book.html#hfile)文件
```
hadoop fs -ls /hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de/i
Found 1 items
/hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de/i/cbb417254e094889b775d71a72187cd2
```

**3.2 StoreFile结构**

`StoreFile`文件是由多个`block`(块)组成的，包括数据块、元数据块、数据索引块、元数据索引块等部分。想直接看细节的可以参考这篇[博文](http://www.nosqlnotes.com/technotes/hbase/hfile/)

![hfile](http://www.nosqlnotes.com/wp-content/uploads/2018/07/HFileV2.png)

**3.3 查看StoreFile**

查看StoreFile文件谢谢：执行 `hbase hfile -v -m -f`命令 
（带上`-p` 参数会打印StoreFile内数据块的内容）[^HFile]内容比较多，但前期有个简单的印象即可。
```
Block index size as per heapsize: 392
reader=/hbase/data/dwa/userInfo/a63da1c7f510d10188a5151b1c2607de/i/cbb417254e094889b775d71a72187cd2,
    compression=none,                           //压缩信息
    cacheConf=CacheConfig:disabled,
    firstKey=001/i:age/1544169592112/Put,
    lastKey=008/i:name/1543826992754/Put,
    avgKeyLen=20,
    avgValueLen=2,
    entries=24,                                 //行*列数
    length=1772
Trailer:                                        //记录StoreFile的基本信息，各block的偏移值
    fileinfoOffset=970,
    loadOnOpenDataOffset=864,
    dataIndexCount=1,
    metaIndexCount=0,
    totalUncomressedBytes=1683,
    entryCount=24,
    compressionCodec=NONE,
    uncompressedDataIndexSize=32,
    numDataIndexLevels=1,
    firstDataBlockOffset=0,
    lastDataBlockOffset=0,
    comparatorClassName=org.apache.hadoop.hbase.KeyValue$KeyComparator,
    majorVersion=2,
    minorVersion=3
Fileinfo:
    BLOOM_FILTER_TYPE = ROW                 //布隆过滤器类型
    DELETE_FAMILY_COUNT = \x00\x00\x00\x00\x00\x00\x00\x00  
    EARLIEST_PUT_TS = \x00\x00\x01gsA\xA4\xED
    KEY_VALUE_VERSION = \x00\x00\x00\x01
    LAST_BLOOM_KEY = 008                    //当前HFile最后的rowKey值
    MAJOR_COMPACTION_KEY = \xFF
    MAX_MEMSTORE_TS_KEY = \x00\x00\x00\x00\x00\x00\x00$
    MAX_SEQ_ID_KEY = 38
    TIMERANGE = 1543826941165....1544169592112
    hfile.AVG_KEY_LEN = 20
    hfile.AVG_VALUE_LEN = 2
    hfile.CREATE_TIME_TS = \x00\x00\x01g\x87\xE6LE
    hfile.LASTKEY = \x00\x03008\x01iname\x00\x00\x01gsBnr\x04
Mid-key: \x00\x03001\x01iage\x00\x00\x01g\x87\xAE\x150\x04
Bloom filter:
    BloomSize: 16
    No of Keys in bloom: 8
    Max Keys for bloom: 13
    Percentage filled: 62%
    Number of chunks: 1
    Comparator: RawBytesComparator
Delete Family Bloom filter:
    Not present
Scanned kv count -> 24
```


### 5 参考链接

1. [hbase在hdfs上的详细目录结构](https://blog.csdn.net/l_15156024189/article/details/83444255)     
2. [Hbase的存储](https://www.cnblogs.com/kxdblog/p/4330930.html)  
3. [HMaster 功能之定期清理archive](https://www.jianshu.com/p/f82aafd7b381)  
4. [HBase高性能随机查询之道 – HFile原理解析](http://www.nosqlnotes.com/technotes/hbase/hfile/)  
5. [HBase Architecture 101 - Write-ahead-Log](http://www.larsgeorge.com/2010/01/hbase-architecture-101-write-ahead-log.html)

[^region]:> [HBase结构](https://hbase.apache.org/book.html#regions.arch)
[^1]:> [region分裂](https://www.jianshu.com/p/c0f79c06e9aa)
[^2]:> [HBASE in HDFS](https://hbase.apache.org/book.html#trouble.namenode.hbase.objects)
[^HFile]:> [HFile格式详解](https://blog.csdn.net/gao_zhen_yu/article/details/7229950)
